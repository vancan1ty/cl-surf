
{{Infobox data structure
|name=AVL tree
|type=tree
|invented_by=[[Georgii Adelson-Velskii|G. M. Adelson-Velskii]] and [[Yevgeniy Landis|E. M. Landis]]
|invented_year=1962
|
|space_avg=O(n)
|space_worst=O(n)
|search_avg=O(log n)
|search_worst=O(log n)
|insert_avg=O(log n)
|insert_worst=O(log n)
|delete_avg=O(log n)
|delete_worst=O(log n)
}}
[[Image:AVLtreef.svg|thumb|right|251px|Example AVL tree]]

In [[computer science]], an '''AVL tree''' (Adelson-Velskii and Landis' tree, named after the inventors) is a [[self-balancing binary search tree]], and it was the first such [[data structure]] to be invented.<ref>[[Robert Sedgewick (computer scientist)|Robert Sedgewick]], ''Algorithms'', Addison-Wesley, 1983, ISBN 0-201-06672-6, page 199, chapter 15: Balanced Trees.</ref> In an AVL tree, the [[tree height|heights]] of the two [[child node|child]] subtrees of any node differ by at most one; if at any time they differ by more than one, rebalancing is done to restore this property. Lookup, insertion, and deletion all take [[big O notation|O]](log ''n'') time in both the average and worst cases, where ''n'' is the number of nodes in the tree prior to the operation. Insertions and deletions may require the tree to be rebalanced by one or more [[tree rotation]]s.

The AVL tree is named after its two [[Soviet Union|Soviet]] inventors, [[Georgii Adelson-Velskii|G. M. Adelson-Velskii]] and [[Yevgeniy Landis|E. M. Landis]], who published it in their 1962 paper "An algorithm for the organization of information".<ref>{{cite journal|last=Adelson-Velskii|first=G.|coauthors=E. M. Landis|year=1962|title=An algorithm for the organization of information|journal=[[Proceedings of the USSR Academy of Sciences]]|volume=146|pages=263–266}} {{ru icon}} English translation by Myron J. Ricci in ''Soviet Math. Doklady'', 3:1259&ndash;1263, 1962.</ref>

AVL trees are often compared with [[red-black tree]]s because both support the same set of operations and take [[big O notation|O]](log ''n'') time for the basic operations.  For lookup-intensive applications, AVL trees are faster than red-black trees because they are more rigidly balanced.<ref>{{cite web|last = Pfaff|first = Ben|title = Performance Analysis of BSTs in System Software| publisher = [[Stanford university|Stanford University]]|year = 2004|month = June|url = http://www.stanford.edu/~blp/papers/libavl.pdf|format = PDF}}</ref> Similar to red-black trees, AVL trees are height-balanced, but in general not [[Weight-balanced tree|weight-balanced]] nor μ-balanced for any <math>\scriptstyle \mu\leq\tfrac12</math>;<ref>[http://cs.stackexchange.com/questions/421/avl-trees-are-not-weight-balanced AVL trees are not weight-balanced? (meaning: AVL trees are not μ-balanced?)] <br>Thereby: A Binary Tree is called <math>\mu</math>-balanced, with <math>0 \le\mu\leq\tfrac12</math>, if for every node <math>N</math>, the inequality
: <math>\frac12-\mu\le\tfrac{|N_l|}{|N|+1}\le \tfrac12+\mu</math>
holds and <math>\mu</math> is minimal with this property. <math>|N|</math> is the number of nodes below the tree with <math>N</math> as root (including the root) and <math>N_l</math> is the left child node of <math>N</math>.</ref> that is, sibling nodes can have hugely differing numbers of descendants.

==Operations==
[[File:BinaryTreeRotations.svg|thumb|300px|Tree rotations]]
Basic operations of an AVL tree involve carrying out the same actions as would be carried out on an unbalanced [[binary search tree]], but modifications are followed by zero or more operations called [[tree rotation]]s, which help to restore the height balance of the subtrees.

===Searching===
Once a node has been found in a balanced tree, the ''next'' or ''previous'' nodes can be explored in [[amortized complexity|amortized]] constant time. Some instances of exploring these "nearby" nodes require traversing up to 2×log(''n'') links (particularly when moving from the rightmost leaf of the root's left sub tree to the leftmost leaf of the root's right sub tree; in the example AVL tree, moving from node 14 to the ''next but one'' node 19 takes 4 steps). However, exploring all ''n'' nodes of the tree in this manner would use each link exactly twice: one traversal to enter the sub tree rooted at that node, another to leave that node's sub tree after having explored it. And since there are ''n''−1 links in any tree, the amortized cost is found to be 2×(''n''−1)/''n'', or approximately 2.

===Insertion===
[[File:AVL Tree Rebalancing.svg|thumb|350px|Pictorial description of how rotations cause rebalancing tree, and then retracing one's steps toward the root updating the balance factor of the nodes. The numbered circles represent the nodes being balanced. The lettered triangles represent subtrees which are themselves balanced BSTs]]

After inserting a node, it is necessary to check each of the node's ancestors for consistency with the rules of AVL. The balance factor is calculated as follows: balanceFactor = height(left subtree) - height(right subtree). For each node checked, if the balance factor remains −1, 0, or +1 then no rotations are necessary. However, if balance factor becomes less than -1 or greater than +1, the subtree rooted at this node is unbalanced. If insertions are performed serially, after each insertion, at most one of the following cases needs to be resolved to restore the entire tree to the rules of AVL.

Suppose inserting one element causes P's balance factor to go out of range. It must be that insertion caused the height of one of P's child nodes to increase by 1 (but not the other). Without loss of generality, assume that the height of L, P's left, was increased. The following procedure can restore balance at P:

  if (balance_factor(L) < -1) {
    // In the illustration to the right,
    // this is the first step in the left-right case.
    rotate_left(L);
  }
  // This brings us to the left-left case.
  rotate_right(P);

The right-left and right-right cases are analogous. The names of the cases refer to the portion of the tree that is reduced in height.

In order to restore the balance factors of all nodes, first observe that all nodes requiring correction lie along the path used during the initial insertion. If the above procedure is applied to nodes along this path, starting from the bottom (i.e. the node furthest away from the root), then every node in the tree will again have a balance factor of -1, 0, or 1.

===Deletion===
Let''' node X''' be the node with the value we need to delete, and let''' node Y''' be a node in the tree we need to find to take node X's place, and let '''node Z''' be the actual node we take out of the tree.

Steps to consider when deleting a node in an AVL tree are the following:
# If '''node X''' is a leaf or has only one child, skip to step 5. (node Z will be node X)
# Otherwise, determine '''node Y''' by finding the largest node in '''node X'''<nowiki/>'s left sub tree (in-order predecessor) or the smallest in its right sub tree (in-order successor).
# Replace '''node X''' with '''node Y''' (remember, tree structure doesn't change here, only the values). In this step,''' node X''' is essentially deleted when its internal values were overwritten with '''node Y'''<nowiki/>'s.
# Choose '''node Z''' to be the old '''node Y'''.
# Attach '''node Z'''<nowiki/>'s subtree to its parent (if it has a subtree). If '''node Z'''<nowiki/>'s parent is null, update root. (node Z is currently root)
# Delete '''node Z'''.
#  Retrace the path back up the tree (starting with node Z's parent) to the root, adjusting the balance factors as needed.
As with all binary trees, a node's in-order successor is the left-most child of its right subtree, and a node's in-order predecessor is the right-most child of its left subtree. In either case, this node will have zero or one children. Delete it according to one of the two simpler cases above.
[[File:binary search tree delete.svg|thumb|640px|center|Deleting a node with two children from a binary search tree using the inorder predecessor (rightmost node in the left subtree, labelled '''6''').]]

In addition to the balancing described above for insertions, if the balance factor for the tree is 2 and that of the left subtree is 0, a right rotation must be performed on P.  The mirror of this case is also necessary.

The retracing can stop if the balance factor becomes −1 or +1 indicating that the height of that subtree has remained unchanged.
If the balance factor becomes 0 then the height of the subtree has decreased by one and the retracing needs to continue.
If the balance factor becomes −2 or +2 then the subtree is unbalanced and needs to be rotated to fix it.
If the rotation leaves the subtree's balance factor at 0 then the retracing towards the root must continue since the height of this subtree has decreased by one.
This is in contrast to an insertion where a rotation resulting in a balance factor of 0 indicated that the subtree's height has remained unchanged.

The time required is O(log ''n'') for lookup, plus a maximum of O(log ''n'') rotations on the way back to the root, so the operation can be completed in O(log ''n'') time.

==Comparison to other structures==
Both AVL trees and red-black trees are self-balancing binary search trees and they are very similar mathematically.<ref>In fact, each AVL tree can be colored red-black.</ref> The operations to balance the trees are different, but both occur on the average in O(1) with maximum in O(log ''n''). The real difference between the two is the limiting height.
For a tree of size <math> n </math>:
*An AVL tree's height is strictly less than:<ref>{{cite book|last=Burkhard|first=Walt|title=Advanced Data Structures|url=http://ieng6.ucsd.edu/~cs100s/public/Notes/CS100s12.pdf|date=Spring 2012|publisher=[http://softreserves.ucsd.edu/ A.S. Soft Reserves], [[UC San Diego]]|location=[[La Jolla]]|page=103|chapter=AVL Dictionary Data Type Implementation}}</ref><ref>{{cite book|last=Knuth|first=Donald E.|title=Sorting and searching|year=2000|publisher=Addison-Wesley|location=Boston [u.a.]|isbn=0-201-89685-0|pages=460|edition=2. ed., 6. printing, newly updated and rev.}}</ref>
*:<math>\log_\varphi(\sqrt 5 (n+2)) - 2 = { \log_2(\sqrt 5 (n+2)) \over \log_2(\varphi) } - 2 = \log_\varphi(2) \cdot \log_2(\sqrt 5 (n+2)) - 2 \approx 1.44\log_2(n+2) - 0.328</math>
*:where <math>\varphi</math> is the [[golden ratio]].
*A [[red-black tree]]'s height is at most <math>2\log_2(n+1)</math><ref>[[Red-black tree#Proof of asymptotic bounds|Proof of asymptotic bounds]]</ref>

AVL trees are more rigidly balanced than [[red-black tree]]s, leading to slower insertion and removal but faster retrieval.

==See also==
*[[tree data structure|Trees]]
*[[Tree rotation]]
*[[Splay tree]]
*[[Scapegoat tree]]
*[[B-tree]]
*[[T-tree]]
*[[List of data structures]]

==References==
<references />

==Further reading==
* [[Donald Knuth]]. ''The Art of Computer Programming'', Volume 3: ''Sorting and Searching'', Third Edition. Addison-Wesley, 1997. ISBN 0-201-89685-0. Pages 458&ndash;475 of section 6.2.3: Balanced Trees.

==External links==
{{Wikibooks|Algorithm Implementation|Trees/AVL tree|AVL tree}}
{{Commons category|AVL-trees}}
*[https://github.com/vilkov/libxdg/wiki xdg library] by Dmitriy Vilkov: Serializable straight C-implementation could easily be taken from this library under [[GNU Lesser General Public License|GNU-LGPL]] and [[Academic Free License|AFL v2.0]] licenses.
*[http://www.nist.gov/dads/HTML/avltree.html Description from the Dictionary of Algorithms and Data Structures]
*[http://github.com/pgrafov/python-avl-tree/ Python Implementation]
*[http://piumarta.com/software/tree/ Single C header file by Ian Piumarta]
*[http://www.strille.net/works/media_technology_projects/avl-tree_2001/ AVL Tree Demonstration]
*[http://webdiis.unizar.es/asignaturas/EDA/AVLTree/avltree.html AVL tree applet – all the operations]
*[http://github.com/fbuihuu/libtree Fast and efficient implementation of AVL Trees]
*[https://github.com/mondrake/Rbppavl PHP Implementation]
*[http://www.codeproject.com/Articles/12347/AVL-Binary-Tree-for-C C++ implementation which can be used as an array]
*[http://code.google.com/p/self-balancing-avl-tree/ Self balancing AVL tree with Concat and Split operations]

{{CS-Trees}}
{{Data structures}}

{{DEFAULTSORT:Avl Tree}}
[[Category:1962 in computer science]]
[[Category:Binary trees]]
[[Category:Soviet inventions]]
